---
title: Data Science Tools
categories:
- General
excerpt: |
  Try to learn how to build even a basic service can be a pain when you don't know what a service is and your python code is still similar to your C++ code.
feature_image: /assets/white.jpg
feature_text: |
  ## A Beginner Data Scientist's Tool Kit
  Tools to make statistical and mathematical models into a small product.
---

## Intro
I have seen more than one people with a good knowledge of applied mathematics trying to get started as a "data scientist". In deed I was one and I can say that I would have really liked to have introductory articles written for people who are not software developers.

That is why I decided to write this little list for beginners. When you haven't heard the term "API" ever,  learning how to write something that you can expose in an url can be much harder that learning about clustering techniques or deep neural networks.

This article is a high-level of some basic software development tools used in industry, particularly, in Data Science/Machine Learning development. It's intended to be an intro for people with little knowledge of programming, but a good understanding of mathematics (so probably not for CS scientists).

This is not a Data Science or Machine Learning intro. I will not be covering algorithms or ML concepts here. 

##### What exactly is a Data Scientist (DS)?
Answering the question in the title of this sub-section is not my objective here. It just happens to be something we need to define, at least in the scope of this article. As the Data Science field is so wide, maybe the question "what is data science?" is easier to answer. I will not delve into that now. If you are interested in what are the different roles in a data team, take a look at the different roles in [this post](https://hackernoon.com/top-10-roles-for-your-data-science-team-e7f05d90d961) by Cassie Kozyrkov. It should give you a good initial idea about what you can find.

This article will be based on a simple definition of "Data Scientist". As there is no standard definition that I am aware of, I will go with a very general idea of *job profiles you could find labeled as "Data Scientist"*.

## General development tools
Python, Jupyter, Git and Anaconda. You will find these 4 tools useful even if you are not planning to work in industry. They will help you keep your work organized and keep the less organized parts of your work in an easy-to-use place (see Jupyter for that). This article will be a list of these basic tools, a little overview and the reasons why I think you will love them.


## Python (including software development knowledge and some of its infinite libraries)
Needless to say, you can spend all the time you want just learning Python. As I see it, the required knowledge here varies depending on what "kind of data scientist" we are talking about. A machine learning engineer or a developer trying to use a ML service *may* need deeper knowledge of python than a data analyst will.

My point here is that you should not prioritize learning every little thing about the language before trying to use it for something. Although I think that  most of us like to super-over-engineer simple functions when learning about a new programming language, for fun and profit.

Unfortunately, I do not have a link to any resource I know to be valuable when learning pyhton. If I find something, I will edit this page to include it.


## Git
Git is a version control system. It allows you to coordinate your work with your team or keep your own code organized by managing the different versions you have. If you find yourself keeping large blocks of code commented "just for now" or "just in case", git might be a thing you need. If you are planning to work in the industry, it is a tool you need.

Starting with Git is really easy. You can just [install it](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git) and start pulling, writing, commiting and pushing code like crazy. Problems may arise when you want to undo something you shouldn't have done, so a little tutorial might be in order if you never used it before. To be honest I just keep forgetting the options I use the least, but the Atlassian has a [great tutorial](https://www.atlassian.com/git/tutorials) (that I still use as documentation) and a very handy [cheat sheet](https://www.atlassian.com/git/tutorials/atlassian-git-cheatsheet)

## Anaconda (virtual environments)
I will write about Anaconda because I know it the best, but I guess any way of creating virtual environments (like python's virtualenv) is good.

If you are installing python packages in your computer, you might have felt a little nervous when installing a new package without knowing if you were just about to break some other thing. Well, virtual environments are your way out of that.

In a virtual environment you can install all the packages you want independently from the ones your computer (or other virtual environments in you computer) uses. Multiple environments can co-exist in the same computer (wouldn't make sense otherwise) each with its own packages.

It also provides some reproducibility for running code. Environments can be cloned and all the packages installed in it can be printed to a file in order to create a new environment similar to the first one. When it comes to portability, virtual environments are not docker (beautiful docker), but they help and are easier to use.

Anaconda's [documentation](https://docs.anaconda.com/anaconda/install/) is pretty good. And, again, [here](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html) is a nice list of commands.


## Jupyter (and why this is not in the "Python" section)
Much like a physical notebook, a Jupyter notebook is an excellent place to write messy stuff. In the case of data science development, you don't have to be running all of your program and loading data and creating your models again just to try little changes in a function. After writing, trying, modifying and polishing, you can always export your now-clean code to aÂ *.py* file.

Here you will be writing code into "cells". Each cell is a place were you can write code and run it. You can run the cells, (that is, execute the code inside the cells) in any order you want. You can create, modify delete cells as you want and run them in any order. Just keep in mind that these notebooks have an "internal state". They remember what is the state of every object in your code.

If I were you, I would install Jupyter using [conda](https://anaconda.org/anaconda/jupyter), the package manager for anaconda.

Lastly, some [keyboard shortcuts](https://cheatography.com/weidadeyue/cheat-sheets/jupyter-notebook/)

<!-- ## Data Bases

## Flask (the easy path to a web api)

## Docker -->
